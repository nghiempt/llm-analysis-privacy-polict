# Unveiling Discrepancies in Android App Data Safety Declarations and Privacy Policies: An In-depth Analysis using Large Language Models

> This paper identifies critical discrepancies in data safety declarations and privacy policies among 600 Android apps, raising concerns about user trust and legal implications. The study explores the potential of advanced techniques, like fine-tuning large language models, to monitor and verify app behaviors against their stated commitments. To promote transparency, the research provides a benchmark dataset and a list of examined Android apps, contributing to a more trustworthy app ecosystem.

![](figure)

*Caption for the example figure with the main results.*


## Abstract

This paper delves into the critical discrepancies observed between data safety declarations and privacy policies across 600 Android applications, bringing to light the issues of incompleteness, incorrectness, and inconsistency. 
Such misalignments undermine user trust and pose severe ethical and legal challenges. 
Our research is a pioneering effort in this domain, posing crucial questions about the potential of technology to rectify these disparities. 
We postulate whether advanced techniques, precisely fine-tuning large language models (LLMs), could be leveraged to monitor and verify app behaviors against their declared commitments, ensuring unity and fortifying trust. 
In our investigation, we comprehensively assess the flexibility and capability of LLMs across multiple training scenarios, establishing ten evaluation cases within four distinct strategies, including Zero-Shot, Manual Label Fine-Tuning, and LLM-generated label fine-tuning. 
As a commitment to transparency and furthering research in this domain, we release a benchmark dataset and maintain a curated list of the examined Android applications. 
Our findings contribute significantly to understanding the alignment of privacy policies and data safety declarations, setting the stage for future informed, transparent, and trustworthy app ecosystems.


## Software implementation

> Briefly describe the software that was written to produce the results of this
> paper.

All source code used to generate the results and figures in the paper are in
the `code` folder.
The calculations and figure generation are all run inside
[Jupyter notebooks](http://jupyter.org/).
The data used in this study is provided in `data` and the sources for the
manuscript text and figures are in `manuscript`.
Results generated by the code are saved in `results`.
See the `README.md` files in each directory for a full description.


## Getting the code